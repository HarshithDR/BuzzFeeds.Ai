{
    "title": "AI Detectors for ChatGPT: Everything You Need to Know",
    "url": "https://www.wired.com/story/ai-detector-chatgpt/",
    "publishedAt": "2024-04-30T11:00:00Z",
    "content": "To revisit this article, visit My Profile, then View saved stories.\nReece Rogers\nDetecting when text has been generated by tools like ChatGPT is a difficult task. Popular artificial- intelligence-detection tools, like GPTZero, may provide some guidance for users by telling them when something was written by a bot and not a human, but even specialized software is not foolproof and can spit out false positives.\nAs a journalist who started covering AI detection over a year ago, I wanted to curate some of WIRED’s best articles on the topic to help readers like you better understand this complicated issue.\nHave even more questions about spotting outputs from ChatGPT and other chatbot tools? Sign up for my AI Unlocked newsletter, and reach out to me directly with anything AI-related that you would like answered or want WIRED to explore more.\nFebruary 2023 by Reece Rogers\nIn this article, which was written about two months after the launch of ChatGPT, I started to grapple with the complexities of AI text detection as well as what the AI revolution might mean for writers who publish online. Edward Tian, the founder behind GPTZero, spoke with me about how his AI detector focuses on factors like text variance and randomness.\nAs you read, focus on the section about text watermarking: “A watermark might be able to designate certain word patterns to be off-limits for the AI text generator.” While a promising idea, the researchers I spoke with were already skeptical about its potential efficacy.\nSeptember 2023 by Christopher Beam\nA fantastic piece from last year’s October issue of WIRED, this article gives you an inside look into Edward Tian’s mindset as he worked to expand GPTZero’s reach and detection capabilities. The focus on how AI has impacted schoolwork is crucial.\nAI text detection is top of mind for many classroom educators as they grade papers and, potentially, forgo essay assignments altogether due to students secretly using chatbots to complete homework assignments. While some students might use generative AI as a brainstorming tool, others are using it to fabricate entire assignments.\nSeptember 2023 by Kate Knibbs\nDo companies have a responsibility to flag products that might be generated by AI? Kate Knibbs investigated how potentially copyright-breaking AI-generated books were being listed for sale on Amazon, even though some startups believed the products could be spotted with special software and removed. One of the core debates about AI detection hinges on whether the potential for false positives—human-written text that’s accidentally flagged as the work of AI—outweighs the benefits of labeling algorithmically generated content.\nAugust 2023 by Amanda Hoover\nGoing beyond just homework assignments, AI-generated text is appearing more in academic journals, where it is often forbidden without a proper disclosure. “AI-written papers could also draw attention away from good work by diluting the pool of scientific literature,” writes Amanda Hoover. One potential strategy for addressing this issue is for developers to build specialized detection tools that search for AI content within peer-reviewed papers.\nOctober 2023 by Kate Knibbs\nWhen I first spoke with researchers last February about watermarks for AI text detection, they were hopeful but cautious about the potential to imprint AI text with specific language patterns that are undetectable by human readers but obvious to detection software. Looking back, their trepidation seems well placed.\nJust a half-year later, Kate Knibbs spoke with multiple sources who were smashing through AI watermarks and demonstrating their underlying weakness as a detection strategy. While not guaranteed to fail, watermarking AI text continues to be difficult to pull off.\nApril 2024 by Amanda Hoover\nOne tool that teachers are trying to use to detect AI-generated classroom work is Turnitin, a plagiarism detection software that added AI spotting capabilities. (Turnitin is owned by Advance, the parent company of Condé Nast, which publishes WIRED.) Amanda Hoover writes, “Chechitelli says a majority of the service’s clients have opted to purchase the AI detection. But the risks of false positives and bias against English learners have led some universities to ditch the tools for now.”\nAI detectors are more likely to falsely label written content from someone whose first language isn’t English as AI than that from someone who’s a native speaker. As developers continue to work on improving AI-detection algorithms, the problem of erroneous results remains a core obstacle to overcome.\nBenj Edwards, Ars Technica\nAdrienne So\nMedea Giordano\nParker Hall\nNavigate election season with our WIRED Politics Lab newsletter and podcast\nA hacker took down North Korea’s internet. Now he’s taking off his mask\nBlowing the whistle on sexual harassment and assault in Antarctica\nThis woman will decide which babies are born\nUpgrading your Mac? Here’s what you should spend your money on\nReece Rogers\nReece Rogers\nBoone Ashworth\nJuliane Bergmann\nLauren Goode\nParker Hall\nReece Rogers\nLouryn Strampe\nSave up to $58 Off TurboTax Online\n20% Off All H&R Block 2024 Tax Software | H&R Block Coupon\nUp to $20 off at Instacart in 2024\nUp to 35% Off Your Order w/ DoorDash Promo Code\n$10 off $100 purchase at Finish Line w/ coupon code\nGroupon discount code: Extra 10% off any size order\nMore From WIRED\nReviews and Guides\n© 2024 Condé Nast. All rights reserved. WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast. Ad Choices"
}